source('H:/COMP120/Lab/Lb07/mastery/mastery-07.R')
source('H:/COMP120/Lab/Lb07/mastery/mastery-07.R')
source('H:/COMP120/Lab/Lb07/mastery/mastery-07.R')
source('H:/COMP120/Lab/Lb07/mastery/mastery-07.R')
be included below.
# Don't forget to add your student id and the name in the file (see placeholders above).
# Write a comment before each block of code that you use to complete
# a given task that explains what the c
library(tidyverse)
library(lubridate)
ardern_tweets <- read_csv("ardern_tweets.csv")
winston_tweets <- read_csv("winston_tweets.csv")
tweets <- ardern_tweets %>%
bind_rows(winston_tweets) %>%
select(created, text, isRetweet, screenName)
tweets$year <- year(tweets$created)
tweets %>%
mutate(year = as.factor(year)) %>%
ggplot(aes(x = year, fill = year)) +
geom_bar() +
ggtitle("Tweets per year") +
xlab("Year") +
ylab("Count")
yearly_tweet_counts <- tweets %>%
group_by(year) %>%
summarise(n = n())
tweets %>%
filter(isRetweet == FALSE) %>%
filter(year == 2013|year == 2014|year == 2015|year == 2016|year == 2017|year == 2018) %>%
ggplot(aes(x=year))+
geom_bar(aes(fill=screenName), position = "dodge")+
xlab("Year")+
ylab("Tweet counts")+
ggtitle("Comparision of tweet counts")
yearly_tweet_counts <- tweets %>%
group_by(year) %>%
summarise(n = n())
yearly_tweet_count_jacinda <- tweets %>%
filter(screenName == "jacindaardern")
group_by(year) %>%
summarise(n = n())
yearly_tweet_counts <- tweets %>%
group_by(year) %>%
summarise(n = n())
yearly_tweet_count_jacinda <- tweets %>%
filter(screenName == "jacindaardern") %>%
group_by(year) %>%
summarise(n = n())
yearly_tweet_count_winston <- tweets %>%
filter(screenName == "winstonpeters") %>%
group_by(year) %>%
summarise(n = n())
tweet_url_counts <- tweets %>%
filter(isRetweet == FALSE) %>%
filter(year == 2013|year == 2014|year == 2015|year == 2016|year == 2017|year == 2018) %>%
count(screenName,year,
hasUrl = ifelse(str_detect(text, "t\\.co"),
1, 0)) %>%
filter(hasUrl == 1) %>%
select(-hasUrl)
tweet_url_counts %>%
ggplot()+
geom_line(mapping = aes(x=year, y=n, col=screenName))+
xlab("Year")+
ylab("Counts of links")+
ggtitle("Comparision of URL counts")
library(tidyverse)
library(lubridate)
ardern_tweets <- read_csv("ardern_tweets.csv")
winston_tweets <- read_csv("winston_tweets.csv")
tweets <- ardern_tweets %>%
bind_rows(winston_tweets) %>%
select(created, text, isRetweet, screenName)
tweets$year <- year(tweets$created)
tweets %>%
mutate(year = as.factor(year)) %>%
ggplot(aes(x = year, fill = year)) +
geom_bar() +
ggtitle("Tweets per year") +
xlab("Year") +
ylab("Count")
yearly_tweet_counts <- tweets %>%
group_by(year) %>%
summarise(n = n())
yearly_tweet_count_jacinda <- tweets %>%
filter(screenName == "jacindaardern") %>%
group_by(year) %>%
summarise(n = n())
yearly_tweet_count_winston <- tweets %>%
filter(screenName == "winstonpeters") %>%
group_by(year) %>%
summarise(n = n())
tweets %>%
filter(isRetweet == FALSE) %>%
filter(year == 2013|year == 2014|year == 2015|year == 2016|year == 2017|year == 2018) %>%
ggplot(aes(x=year))+
geom_bar(aes(fill=screenName), position = "dodge")+
xlab("Year")+
ylab("Tweet counts")+
ggtitle("Comparision of tweet counts")
tweet_url_counts <- tweets %>%
filter(isRetweet == FALSE) %>%
filter(year == 2013|year == 2014|year == 2015|year == 2016|year == 2017|year == 2018) %>%
count(screenName,year,
hasUrl = ifelse(str_detect(text, "t\\.co"),
1, 0)) %>%
filter(hasUrl == 1) %>%
select(-hasUrl)
tweet_url_counts %>%
ggplot()+
geom_line(mapping = aes(x=year, y=n, col=screenName))+
xlab("Year")+
ylab("Counts of links")+
ggtitle("Comparision of URL counts")
setwd("H:/COMP120/Lab/lab09")
# Load the appropriate packages/libraries for this mastery task. Code for one of them is given below.
library(tidyverse)
# A random seed has been set for you. You must execute this line before creating training and test data so that the results are reproducible (i.e., will provide the same results everytime and it is easy to check the answers)
set.seed(1001) ## FIX THE RANDOM NUMBER GENERATOR FOR REPRODUCIBILITY
# Write code to create diamonds2 dataset. Also, write code to partition this dataset into the training and test data
diamonds2 <- diamonds %>% filter(carat <= 2.5)
train <- diamonds2 %>% sample_frac(0.9)
test <- diamonds2 %>% setdiff(train)
f <- price ~ carat
# a)	Write code to construct the model using the training dataset.
model1 <- lm(f, train)
summary(model1)
# d)	Write code to obtain the R-squared value for the training dataset.
mdl1 <- summary(model1)
mdl1$r.squared
# f)	Write code to predict the outcomes for the test dataset.
yhat <- predict(model1, test)
# g)	Write code to obtain the R-squared value for the test dataset.
# Compute R square statustic for the  data
rsqr <- function(y, yhat) {
ss.res <- sum((y - yhat)^2)
ss.tot <- sum((y - mean(y))^2)
1 - ss.res / ss.tot
}
rsqr(test$price, yhat)
#h)	Write code to generate the residual plot for the test dataset.
test_mod <- test %>% mutate(residual = price - yhat)
# Visualise the residual plot
ggplot(test_mod, aes(x=price, y=residual)) +
geom_point(aes(alpha=0.1)) +
geom_abline(slope = 0, intercept=0, col = "red") +
ggtitle("Diamond Price vs. residual") +
xlab("Diamond Price") +
ylab("Residual")
ggplot(test_mod, aes(price, carat))+
geom_point(col="blue")+
geom_smooth(method = "lm", se=FALSE, col="red")+
ggtitle("Price vs carat")
# Code and comments for the second model, a random forest model (model2) for question 2 - indicate the
# sub-questions you are answering - e.g. #a), #b) and #c)
#a. construct the model using the training dataset
model2 <- randomForest(f, train, ntree=100)
#b.
mean(model2$rsq)
# Code and comments for the second model, a random forest model (model2) for question 2 - indicate the
# sub-questions you are answering - e.g. #a), #b) and #c)
#a. construct the model using the training dataset
model2 <- randomForest(f, train, ntree=100)
